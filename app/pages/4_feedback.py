# app/pages/4_feedback.py
import streamlit as st
from utils.services import (
    get_supabase_client,
    get_or_create_user_id,
    get_month_summary,
)
from utils.ui import setup_page
import pandas as pd
from datetime import date, timedelta
from supabase import create_client, Client

# ãƒšãƒ¼ã‚¸è¨­å®š
setup_page(
    page_title="ğŸ“Š ä»Šæœˆã®æŒ¯ã‚Šè¿”ã‚Š",
    page_icon="ğŸ˜º",
    show_home=True,
    home_href="/",
    add_title_spacer=True,
)

# Supabaseæ¥ç¶š
supabase = get_supabase_client()

# ===================================
# ä»Šé€±ã¨å…ˆé€±ã®é¤Œãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
# ===================================
try:
    # é–¢æ•°å‘¼ã³å‡ºã—
    result = supabase.rpc("weekly_points_users").execute()

    # DataFrameã«å¤‰æ›
    df = pd.DataFrame(result.data)

    # ä»Šæ—¥ã®æ—¥ä»˜
    today = date.today()

    # ä»Šé€±ã®æœˆæ›œã¨å…ˆé€±ã®æœˆæ›œã‚’è¨ˆç®—
    monday_this_week = today - timedelta(days=today.weekday())
    monday_last_week = monday_this_week - timedelta(weeks=1)

    # å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®UUIDâ˜…â˜…â˜…å¾Œã§å¤‰æ›´
    target_user_id = get_or_create_user_id()

    # ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã ã‘æŠ½å‡º
    user_df = df[df["user_id"] == target_user_id]

    # ä»Šé€±ã¨å…ˆé€±ã®ãƒã‚¤ãƒ³ãƒˆæŠ½å‡ºï¼ˆç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ï¼‰
    points_this_week = user_df.loc[user_df["week_start"] == monday_this_week.isoformat(), "total_points"].sum()
    points_last_week = user_df.loc[user_df["week_start"] == monday_last_week.isoformat(), "total_points"].sum()

    # è¡¨ç¤º
    print("=== ä»Šé€±ã®ãƒã‚¤ãƒ³ãƒˆ ===")
    print(points_this_week)

    print("=== å…ˆé€±ã®ãƒã‚¤ãƒ³ãƒˆ ===")
    print(points_last_week)
        
except Exception as e:
        st.error(f"âŒ é€±æ¬¡ãƒã‚¤ãƒ³ãƒˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# =========================
# ç”ŸæˆAIåˆ†æç”¨ãƒ­ã‚¸ãƒƒã‚¯
# =========================    
## ---------------------------------------------
## A. ãƒ­ã‚°å–å¾—ã¨æ•´å½¢ã®ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
## ---------------------------------------------

def fetch_user_logs_for_analysis(user_id: str, week_start_iso: str) -> List[Dict[str, Any]]:
    """
    Supabaseã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é€±é–“ãƒ­ã‚°ã¨é–¢é€£ã™ã‚‹æ„Ÿæƒ…åã‚’å–å¾—ã™ã‚‹
    """
    try:
        # mood_register_log ã‹ã‚‰ãƒ¡ãƒ¢ã¨ä½œæˆæ—¥æ™‚ã‚’å–å¾—ã—ã€
        # after_mood_master ã‹ã‚‰æ„Ÿæƒ…åï¼ˆmood_nameï¼‰ã‚’å–å¾—ï¼ˆå¤–éƒ¨ã‚­ãƒ¼çµåˆï¼‰
        logs_response = (
            supabase.table("mood_register_log")
            .select("created_at, note, after_mood_master(mood_name)") 
            .eq("user_id", user_id)
            .gte("created_at", week_start_iso) # ä»Šé€±ã®æœˆæ›œæ—¥ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
            .order("created_at", desc=True)
            .execute()
        )
        return logs_response.data
    
    except Exception as e:
        st.error(f"åˆ†æç”¨ãƒ­ã‚°ã®å–å¾—ã«å¤±æ•—: {e}")
        return []

def format_logs_for_ai(data: List[Dict[str, Any]]) -> str:
    """å–å¾—ã—ãŸãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’AIå‘ã‘ã®ä¸€ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢ã™ã‚‹"""
    formatted_logs = []
    for item in data:
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’YYYY-MM-DDå½¢å¼ã«æ•´å½¢
        time = item['created_at'][:10] 
        # æ„Ÿæƒ…åã‚’å–å¾—ï¼ˆå¤–éƒ¨çµåˆã§å–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
        mood = item.get('after_mood_master', {}).get('mood_name', 'ä¸æ˜')
        note = item.get('note', 'ï¼ˆè¨˜è¿°ãªã—ï¼‰')
        
        formatted_logs.append(f"æ—¥æ™‚: {time}, æ„Ÿæƒ…: {mood}, å‡ºæ¥äº‹/ãƒ¡ãƒ¢: {note}")
        
    log_text = "\n".join(formatted_logs)
    return log_text


## ---------------------------------------------
## B. ç”ŸæˆAI API å‘¼ã³å‡ºã—é–¢æ•°
## ---------------------------------------------

def analyze_mood_logs(logs_text: str) -> str:
    """Gemini APIã‚’å‘¼ã³å‡ºã—ã€åˆ†æçµæœã‚’è¿”ã™"""
    
    # èªè¨¼æƒ…å ±ã‚’ secrets.toml ã‹ã‚‰å–å¾—
    if "OPENAI_API_KEY" not in st.secrets:
        return "ğŸš¨ OPENAI_API_KEY ãŒ secrets.toml ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    try:
        client = OpenAI()

        # AIã¸ã®æŒ‡ç¤ºæ–‡
        system_instruction = (
            "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—åˆ†ãƒ­ã‚°ã‚’åˆ†æã™ã‚‹å„ªç§€ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ "
            "ä»¥ä¸‹ã®ã‚ªãƒãƒãƒˆãƒšãƒ­ã‚°ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®31æ—¥é–“ã®å…¥åŠ›ã—ãŸçŠ¶æ³ã«ã¨ã‚‚ãªã†èº«ä½“çŠ¶æ…‹ã€æ„Ÿæƒ…ã®å‚¾å‘ã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"
            "ã¾ãŸã€ãã®çŠ¶æ…‹ã‹ã‚‰æ”¹å–„ã™ã‚‹ã®ã«æœ€é©ãªè¡Œå‹•æ¡ˆã‚’ææ¡ˆã—ã¦ãã ã•ã„"
            "åˆ†æçµæœã¯Markdownå½¢å¼ã§ã€3è¡Œã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
        
        prompt = (
            f"{system_instruction}\n\n"
            f"--- [ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—åˆ†ãƒ­ã‚°ï¼ˆå…¨{len(logs_text.splitlines())}ä»¶ï¼‰] ---\n"
            f"{logs_text}\n"
        )

        output_analysis_result = client.models.generate_content(
            model='gpt-5 nano',
            contents=prompt
        )
        
        return output_analysis_result.text

    except Exception as e:
        return f"AIåˆ†æã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {e}"

# =========================
# æœˆæ¬¡ã‚µãƒãƒªå–å¾—
# =========================

summary = get_month_summary(supabase, user_id)
total_records = summary["total_records"]
total_points = summary["total_points"]

## ---------------------------------------------
## C. Streamlit ã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
## ---------------------------------------------

# =========================
# ã‚µãƒãƒªè¡¨ç¤º
# =========================

st.markdown("### ğŸ“ˆ ä»Šé€±ã®è¨˜éŒ²")

col1, col2 = st.columns(2)

with col1:
    st.metric(
        label="è¨˜éŒ²å›æ•°",
        value=f"{total_records}å›"
    )

with col2:
    st.metric(
        label="ç²å¾—ãƒã‚¤ãƒ³ãƒˆ",
        value=f"{total_weekly_points}pt"
    )

# =========================
# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# =========================

st.markdown("---")

if total_records == 0:
    st.info("ğŸ“ ã¾ã è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ°—åˆ†ã‚’è¨˜éŒ²ã—ã¦çŒ«æ§˜ã¨ä¸€ç·’ã«å‰å‘ãã«ãªã‚ã†ï¼")
elif total_records < 5:
    st.success("ğŸŒ± è¨˜éŒ²ã‚’å§‹ã‚ã¾ã—ãŸã­ï¼ã“ã®èª¿å­ã§ç¶šã‘ã¾ã—ã‚‡ã†ï¼")
elif total_records < 10:
    st.success("ğŸŒ¿ é †èª¿ã«è¨˜éŒ²ãŒç¶šã„ã¦ã„ã¾ã™ï¼ç´ æ™´ã‚‰ã—ã„ï¼")
else:
    st.success("ğŸŒŸ ãŸãã•ã‚“è¨˜éŒ²ã—ã¦ã„ã¾ã™ã­ï¼ç¶™ç¶šã¯åŠ›ãªã‚Šï¼")

# 2. åˆ†ææœŸé–“ï¼ˆä»Šé€±ï¼‰ã®æ±ºå®š
week_start_iso = get_start_of_week()

# 3. ãƒ­ã‚°ã®å–å¾—
st.subheader(f"ğŸ“… åˆ†æå¯¾è±¡æœŸé–“: {week_start_iso} ä»¥é™ã®ãƒ­ã‚°")
raw_logs_data = fetch_user_logs_for_analysis(current_user_id, week_start_iso)

if not raw_logs_data:
    st.info("åˆ†æã™ã‚‹ãŸã‚ã®ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

# 4. ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
user_log_text = format_logs_for_ai(raw_logs_data)

# 5. AIåˆ†æã®å®Ÿè¡Œã¨è¡¨ç¤º
st.markdown("---")
st.header("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

if st.button("AIåˆ†æã‚’å®Ÿè¡Œã™ã‚‹", type="primary"):
    
    # APIå‘¼ã³å‡ºã—ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€st.status ã§ãƒ©ãƒƒãƒ—ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¾…æ©Ÿã‚’ä¿ƒã™
    with st.status("AIãŒå–å¾—ã—ãŸãƒ­ã‚°ã‚’åˆ†æä¸­ã§ã™...", expanded=True) as status:
        
        # ãƒ­ã‚°ã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        status.update(label="ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’AIã«æ¸¡ã™å½¢å¼ã«æ•´å½¢ä¸­...", state="running")
        st.code(user_log_text) # æ¸¡ã™ãƒ­ã‚°ã‚’ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
        
        # APIå‘¼ã³å‡ºã—
        status.update(label="Gemini APIã‚’å‘¼ã³å‡ºã—ä¸­...", state="running")
        analysis_report = analyze_mood_logs(user_log_text)
        
        # å®Œäº†
        status.update(label="åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼", state="complete", expanded=False)
        
    st.markdown("## ğŸ¤– AIåˆ†æçµæœ")
    st.markdown(analysis_report)
    
else:
    st.info("ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

# =========================
# ä½™åŠ›å¯¾å¿œ: è©³ç´°æƒ…å ±
# =========================

with st.expander("ğŸ“‹ è©³ç´°æƒ…å ±ã‚’è¦‹ã‚‹ï¼ˆé–‹ç™ºä¸­ï¼‰", expanded=False):
    st.markdown("""
    **å°†æ¥å®Ÿè£…äºˆå®šã®æ©Ÿèƒ½:**
    - ã‚ˆãé¸ã‚“ã ã‚ªãƒãƒãƒˆãƒšTOP3
    - ã‚ˆãä¼šã£ãŸçŒ«TOP3
    - é€±ã”ã¨ã®è¨˜éŒ²æ¨ç§»ã‚°ãƒ©ãƒ•
    - æ°—åˆ†ã®å¤‰åŒ–ãƒˆãƒ¬ãƒ³ãƒ‰
    
    â€» åˆ¥ãƒ¡ãƒ³ãƒãƒ¼ãŒå®Ÿè£…äºˆå®šã§ã™
    """)

# =========================
# ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
# =========================

st.markdown("---")

if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ã¸æˆ»ã‚‹", use_container_width=True, type="primary"):
    st.switch_page("main.py")